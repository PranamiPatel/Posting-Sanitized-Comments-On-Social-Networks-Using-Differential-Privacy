{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-03-17T04:11:55.028032Z",
          "iopub.status.busy": "2025-03-17T04:11:55.027677Z",
          "iopub.status.idle": "2025-03-17T04:12:16.021525Z",
          "shell.execute_reply": "2025-03-17T04:12:16.020609Z",
          "shell.execute_reply.started": "2025-03-17T04:11:55.027965Z"
        },
        "id": "x0a9nDTM9WyW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from datasets import Dataset\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:12:16.023433Z",
          "iopub.status.busy": "2025-03-17T04:12:16.022742Z",
          "iopub.status.idle": "2025-03-17T04:12:16.519478Z",
          "shell.execute_reply": "2025-03-17T04:12:16.518403Z",
          "shell.execute_reply.started": "2025-03-17T04:12:16.023398Z"
        },
        "id": "CQFOUrvG9Wyf"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/kaggle/input/tweet-dataset/Tweets Dataset.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:12:19.909714Z",
          "iopub.status.busy": "2025-03-17T04:12:19.909406Z",
          "iopub.status.idle": "2025-03-17T04:12:19.922188Z",
          "shell.execute_reply": "2025-03-17T04:12:19.921250Z",
          "shell.execute_reply.started": "2025-03-17T04:12:19.909686Z"
        },
        "id": "Y4TQfv6D9Wyi"
      },
      "outputs": [],
      "source": [
        "data['Party'] = data['Party'].map({'Democrat' : 0, 'Republican' : 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:12:22.574648Z",
          "iopub.status.busy": "2025-03-17T04:12:22.574329Z",
          "iopub.status.idle": "2025-03-17T04:12:22.589383Z",
          "shell.execute_reply": "2025-03-17T04:12:22.588593Z",
          "shell.execute_reply.started": "2025-03-17T04:12:22.574619Z"
        },
        "id": "DFSrxKMe9Wyk"
      },
      "outputs": [],
      "source": [
        "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:12:26.622535Z",
          "iopub.status.busy": "2025-03-17T04:12:26.622241Z",
          "iopub.status.idle": "2025-03-17T04:12:26.775901Z",
          "shell.execute_reply": "2025-03-17T04:12:26.775052Z",
          "shell.execute_reply.started": "2025-03-17T04:12:26.622503Z"
        },
        "id": "A0D_mAad9Wyl"
      },
      "outputs": [],
      "source": [
        "# Convert to Hugging Face Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_data)\n",
        "val_dataset = Dataset.from_pandas(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:12:28.419432Z",
          "iopub.status.busy": "2025-03-17T04:12:28.419126Z",
          "iopub.status.idle": "2025-03-17T04:12:29.985605Z",
          "shell.execute_reply": "2025-03-17T04:12:29.984941Z",
          "shell.execute_reply.started": "2025-03-17T04:12:28.419408Z"
        },
        "id": "ASYV61dr9Wym"
      },
      "outputs": [],
      "source": [
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:12:30.728020Z",
          "iopub.status.busy": "2025-03-17T04:12:30.727622Z",
          "iopub.status.idle": "2025-03-17T04:13:24.252934Z",
          "shell.execute_reply": "2025-03-17T04:13:24.252063Z",
          "shell.execute_reply.started": "2025-03-17T04:12:30.727965Z"
        },
        "id": "cFZBo-R29Wyn"
      },
      "outputs": [],
      "source": [
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"Tweet\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:13:24.254636Z",
          "iopub.status.busy": "2025-03-17T04:13:24.254298Z",
          "iopub.status.idle": "2025-03-17T04:13:24.260000Z",
          "shell.execute_reply": "2025-03-17T04:13:24.258963Z",
          "shell.execute_reply.started": "2025-03-17T04:13:24.254600Z"
        },
        "id": "x1A9C0RJ9Wyp"
      },
      "outputs": [],
      "source": [
        "# Set the format for PyTorch\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'Party'])\n",
        "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'Party'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:13:24.261970Z",
          "iopub.status.busy": "2025-03-17T04:13:24.261678Z",
          "iopub.status.idle": "2025-03-17T04:13:24.275100Z",
          "shell.execute_reply": "2025-03-17T04:13:24.274318Z",
          "shell.execute_reply.started": "2025-03-17T04:13:24.261943Z"
        },
        "id": "f1_gixLD9Wyr"
      },
      "outputs": [],
      "source": [
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:13:24.276679Z",
          "iopub.status.busy": "2025-03-17T04:13:24.276400Z",
          "iopub.status.idle": "2025-03-17T04:13:26.600656Z",
          "shell.execute_reply": "2025-03-17T04:13:26.599780Z",
          "shell.execute_reply.started": "2025-03-17T04:13:24.276651Z"
        },
        "id": "8c13bHhR9Wys"
      },
      "outputs": [],
      "source": [
        "# Load the BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:13:26.601833Z",
          "iopub.status.busy": "2025-03-17T04:13:26.601554Z",
          "iopub.status.idle": "2025-03-17T04:13:26.609195Z",
          "shell.execute_reply": "2025-03-17T04:13:26.608117Z",
          "shell.execute_reply.started": "2025-03-17T04:13:26.601809Z"
        },
        "id": "MNNnkOnC9Wyt"
      },
      "outputs": [],
      "source": [
        "# Set up the optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "total_steps = len(train_loader) * 3  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:13:26.610526Z",
          "iopub.status.busy": "2025-03-17T04:13:26.610275Z",
          "iopub.status.idle": "2025-03-17T04:13:27.011700Z",
          "shell.execute_reply": "2025-03-17T04:13:27.010929Z",
          "shell.execute_reply.started": "2025-03-17T04:13:26.610488Z"
        },
        "id": "8YLHGC2Q9Wyu"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:13:27.012595Z",
          "iopub.status.busy": "2025-03-17T04:13:27.012383Z",
          "iopub.status.idle": "2025-03-17T04:58:04.846645Z",
          "shell.execute_reply": "2025-03-17T04:58:04.845775Z",
          "shell.execute_reply.started": "2025-03-17T04:13:27.012578Z"
        },
        "id": "SCCcrf7m9Wyv"
      },
      "outputs": [],
      "source": [
        "best_val_accuracy = 0\n",
        "\n",
        "for epoch in range(3):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['Party'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}, Average Training Loss: {avg_train_loss}\")\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_preds, val_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['Party'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "    print(f\"Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "    # Save the best model to avoid overfitting\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        model.save_pretrained(\"/kaggle/working/bert\")\n",
        "        tokenizer.save_pretrained(\"/kaggle/working/token\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:58:04.849218Z",
          "iopub.status.busy": "2025-03-17T04:58:04.848935Z",
          "iopub.status.idle": "2025-03-17T04:59:03.422997Z",
          "shell.execute_reply": "2025-03-17T04:59:03.422234Z",
          "shell.execute_reply.started": "2025-03-17T04:58:04.849194Z"
        },
        "id": "cV1eOQd29Wyw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "val_preds, val_labels = [], []\n",
        "\n",
        "with torch.no_grad():  # Disable gradient computation\n",
        "    for batch in val_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['Party'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Get predicted labels by finding the index with the highest logit value\n",
        "        preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "        # Store predictions and labels\n",
        "        val_preds.extend(preds.cpu().numpy())\n",
        "        val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate accuracy\n",
        "val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "print(f\"Validation Accuracy: {val_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:59:03.424701Z",
          "iopub.status.busy": "2025-03-17T04:59:03.424340Z",
          "iopub.status.idle": "2025-03-17T04:59:03.429147Z",
          "shell.execute_reply": "2025-03-17T04:59:03.428256Z",
          "shell.execute_reply.started": "2025-03-17T04:59:03.424665Z"
        },
        "id": "_5xGiYCp9Wyw"
      },
      "outputs": [],
      "source": [
        "def load_model():\n",
        "    model = BertForSequenceClassification.from_pretrained(\"/kaggle/working/bert\")\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"/kaggle/working/token\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:59:03.430357Z",
          "iopub.status.busy": "2025-03-17T04:59:03.430074Z",
          "iopub.status.idle": "2025-03-17T04:59:03.693373Z",
          "shell.execute_reply": "2025-03-17T04:59:03.692677Z",
          "shell.execute_reply.started": "2025-03-17T04:59:03.430328Z"
        },
        "id": "oW6sTfDh9Wyx"
      },
      "outputs": [],
      "source": [
        "model, tokenizer = load_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:59:03.694609Z",
          "iopub.status.busy": "2025-03-17T04:59:03.694311Z",
          "iopub.status.idle": "2025-03-17T04:59:03.699420Z",
          "shell.execute_reply": "2025-03-17T04:59:03.698596Z",
          "shell.execute_reply.started": "2025-03-17T04:59:03.694579Z"
        },
        "id": "ar9pnCi59Wyx"
      },
      "outputs": [],
      "source": [
        "# Predict gender function (Male or Female)\n",
        "def predict_party(comment, model, tokenizer, device):\n",
        "    model.eval()\n",
        "    encoding = tokenizer(comment, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "    input_ids = encoding[\"input_ids\"].to(device)\n",
        "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        prediction = torch.argmax(outputs.logits, dim=1).cpu().item()\n",
        "    return \"Democrat\" if prediction == 0 else \"Republican\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:59:03.700567Z",
          "iopub.status.busy": "2025-03-17T04:59:03.700290Z",
          "iopub.status.idle": "2025-03-17T04:59:03.715125Z",
          "shell.execute_reply": "2025-03-17T04:59:03.714278Z",
          "shell.execute_reply.started": "2025-03-17T04:59:03.700539Z"
        },
        "id": "vY98um-W9Wyy"
      },
      "outputs": [],
      "source": [
        "# Predict gender probability function (Male, Female probabilities)\n",
        "def predict_prob(text, model, tokenizer, device, max_length=128):\n",
        "    model.eval()\n",
        "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        softmax = torch.nn.Softmax(dim=1)\n",
        "        probabilities = softmax(outputs.logits).cpu().numpy()\n",
        "    return probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:59:03.716431Z",
          "iopub.status.busy": "2025-03-17T04:59:03.716136Z",
          "iopub.status.idle": "2025-03-17T04:59:03.733732Z",
          "shell.execute_reply": "2025-03-17T04:59:03.733082Z",
          "shell.execute_reply.started": "2025-03-17T04:59:03.716389Z"
        },
        "id": "I-4Xwrd09Wyy"
      },
      "outputs": [],
      "source": [
        "# Predict instance function (Wrapper to call predict_gender_prob)\n",
        "def predict_instance(text, model, tokenizer, device):\n",
        "    preds = predict_gender_prob(text, model, tokenizer, device)\n",
        "    # Return as dictionary with 'Male' and 'Female' probabilities\n",
        "    return {\n",
        "        \"Democrat Probability\": preds[0][0],  # Probability for Male (class 0)\n",
        "        \"Republican Probability\": preds[0][1]  # Probability for Female (class 1)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:59:03.734686Z",
          "iopub.status.busy": "2025-03-17T04:59:03.734416Z",
          "iopub.status.idle": "2025-03-17T04:59:03.793792Z",
          "shell.execute_reply": "2025-03-17T04:59:03.792590Z",
          "shell.execute_reply.started": "2025-03-17T04:59:03.734657Z"
        },
        "id": "Ojp1jTer9Wyy"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "text_sample = \"Today, Senate Dems vote to #SaveTheInternet. Proud to support similar #NetNeutrality legislation here in the Houseâ€¦ https://t.co/n3tggDLU1L\"\n",
        "predict_party(text_sample, model, tokenizer, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T04:59:03.795175Z",
          "iopub.status.busy": "2025-03-17T04:59:03.794838Z",
          "iopub.status.idle": "2025-03-17T04:59:03.811891Z",
          "shell.execute_reply": "2025-03-17T04:59:03.811046Z",
          "shell.execute_reply.started": "2025-03-17T04:59:03.795145Z"
        },
        "id": "mF2AAVLl9Wy0"
      },
      "outputs": [],
      "source": [
        "txt = \"Check out my op-ed on need for End Executive Overreach Act: The White House is crippling our economy https://t.co/XCmjLB8Qyd via @DCExaminer\"\n",
        "predict_party(txt, model, tokenizer, device)"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 6664587,
          "sourceId": 10746463,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30919,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python [conda env:anaconda3] *",
      "language": "python",
      "name": "conda-env-anaconda3-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}