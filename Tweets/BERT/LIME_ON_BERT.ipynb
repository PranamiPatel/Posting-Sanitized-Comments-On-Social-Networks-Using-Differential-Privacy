{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 11061219,
          "sourceType": "datasetVersion",
          "datasetId": 6891955
        },
        {
          "sourceId": 11061231,
          "sourceType": "datasetVersion",
          "datasetId": 6891965
        },
        {
          "sourceId": 11061249,
          "sourceType": "datasetVersion",
          "datasetId": 6891981
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from datasets import Dataset\n",
        "import numpy as np"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:27:12.209764Z",
          "iopub.execute_input": "2025-03-19T17:27:12.210070Z",
          "iopub.status.idle": "2025-03-19T17:27:32.905046Z",
          "shell.execute_reply.started": "2025-03-19T17:27:12.210044Z",
          "shell.execute_reply": "2025-03-19T17:27:32.904379Z"
        },
        "id": "XI1J7spU-XoY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/kaggle/input/tweet-dataset/Tweets Dataset.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:27:32.905997Z",
          "iopub.execute_input": "2025-03-19T17:27:32.906454Z",
          "iopub.status.idle": "2025-03-19T17:27:33.345500Z",
          "shell.execute_reply.started": "2025-03-19T17:27:32.906432Z",
          "shell.execute_reply": "2025-03-19T17:27:33.344811Z"
        },
        "id": "uw69-Fjc-Xob"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data['Party'] = data['Party'].map({'Democrat' : 0, 'Republican' : 1})"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:27:33.346709Z",
          "iopub.execute_input": "2025-03-19T17:27:33.346993Z",
          "iopub.status.idle": "2025-03-19T17:27:33.359189Z",
          "shell.execute_reply.started": "2025-03-19T17:27:33.346971Z",
          "shell.execute_reply": "2025-03-19T17:27:33.358542Z"
        },
        "id": "bsFVOC78-Xoc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:27:33.360225Z",
          "iopub.execute_input": "2025-03-19T17:27:33.360452Z",
          "iopub.status.idle": "2025-03-19T17:27:33.379325Z",
          "shell.execute_reply.started": "2025-03-19T17:27:33.360432Z",
          "shell.execute_reply": "2025-03-19T17:27:33.378673Z"
        },
        "id": "gzGXZpJ2-Xoc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to Hugging Face Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_data)\n",
        "val_dataset = Dataset.from_pandas(val_data)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:27:33.380148Z",
          "iopub.execute_input": "2025-03-19T17:27:33.380427Z",
          "iopub.status.idle": "2025-03-19T17:27:33.532935Z",
          "shell.execute_reply.started": "2025-03-19T17:27:33.380399Z",
          "shell.execute_reply": "2025-03-19T17:27:33.532245Z"
        },
        "id": "qjlC7SiH-Xoc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:27:33.533703Z",
          "iopub.execute_input": "2025-03-19T17:27:33.534004Z",
          "iopub.status.idle": "2025-03-19T17:27:34.992522Z",
          "shell.execute_reply.started": "2025-03-19T17:27:33.533975Z",
          "shell.execute_reply": "2025-03-19T17:27:34.991919Z"
        },
        "id": "ugqWox7o-Xoc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"Tweet\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:27:34.993253Z",
          "iopub.execute_input": "2025-03-19T17:27:34.993466Z",
          "iopub.status.idle": "2025-03-19T17:28:27.371880Z",
          "shell.execute_reply.started": "2025-03-19T17:27:34.993448Z",
          "shell.execute_reply": "2025-03-19T17:28:27.371005Z"
        },
        "id": "BggIE2aO-Xod"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the format for PyTorch\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'Party'])\n",
        "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'Party'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:27.374140Z",
          "iopub.execute_input": "2025-03-19T17:28:27.374392Z",
          "iopub.status.idle": "2025-03-19T17:28:27.379538Z",
          "shell.execute_reply.started": "2025-03-19T17:28:27.374357Z",
          "shell.execute_reply": "2025-03-19T17:28:27.378816Z"
        },
        "id": "FcwdrnoH-Xod"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:27.380948Z",
          "iopub.execute_input": "2025-03-19T17:28:27.381232Z",
          "iopub.status.idle": "2025-03-19T17:28:27.398033Z",
          "shell.execute_reply.started": "2025-03-19T17:28:27.381212Z",
          "shell.execute_reply": "2025-03-19T17:28:27.397360Z"
        },
        "id": "TOXfrYmT-Xod"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:27.398895Z",
          "iopub.execute_input": "2025-03-19T17:28:27.399177Z",
          "iopub.status.idle": "2025-03-19T17:28:29.885380Z",
          "shell.execute_reply.started": "2025-03-19T17:28:27.399149Z",
          "shell.execute_reply": "2025-03-19T17:28:29.884783Z"
        },
        "id": "fRYll12w-Xoe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "total_steps = len(train_loader) * 3  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:29.886161Z",
          "iopub.execute_input": "2025-03-19T17:28:29.886480Z",
          "iopub.status.idle": "2025-03-19T17:28:29.893579Z",
          "shell.execute_reply.started": "2025-03-19T17:28:29.886451Z",
          "shell.execute_reply": "2025-03-19T17:28:29.892813Z"
        },
        "id": "k9p6UR0h-Xoe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:29.894393Z",
          "iopub.execute_input": "2025-03-19T17:28:29.894659Z",
          "iopub.status.idle": "2025-03-19T17:28:30.296640Z",
          "shell.execute_reply.started": "2025-03-19T17:28:29.894615Z",
          "shell.execute_reply": "2025-03-19T17:28:30.295804Z"
        },
        "id": "pNercmAL-Xoe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model():\n",
        "    model = BertForSequenceClassification.from_pretrained(\"/kaggle/input/bert-tweet\")\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"/kaggle/input/token-tweet\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:30.297554Z",
          "iopub.execute_input": "2025-03-19T17:28:30.297905Z",
          "iopub.status.idle": "2025-03-19T17:28:30.301934Z",
          "shell.execute_reply.started": "2025-03-19T17:28:30.297873Z",
          "shell.execute_reply": "2025-03-19T17:28:30.301135Z"
        },
        "id": "OnmWTS2H-Xoe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = load_model()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:30.302637Z",
          "iopub.execute_input": "2025-03-19T17:28:30.302913Z",
          "iopub.status.idle": "2025-03-19T17:28:34.162044Z",
          "shell.execute_reply.started": "2025-03-19T17:28:30.302893Z",
          "shell.execute_reply": "2025-03-19T17:28:34.161310Z"
        },
        "id": "a1OC8QDn-Xoe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict gender function (Male or Female)\n",
        "def predict_male_or_female(comment, model, tokenizer, device):\n",
        "    model.eval()\n",
        "    encoding = tokenizer(comment, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "    input_ids = encoding[\"input_ids\"].to(device)\n",
        "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        prediction = torch.argmax(outputs.logits, dim=1).cpu().item()\n",
        "    return \"Democrat\" if prediction == 0 else \"Republican\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:34.162920Z",
          "iopub.execute_input": "2025-03-19T17:28:34.163217Z",
          "iopub.status.idle": "2025-03-19T17:28:34.167852Z",
          "shell.execute_reply.started": "2025-03-19T17:28:34.163188Z",
          "shell.execute_reply": "2025-03-19T17:28:34.167199Z"
        },
        "id": "9bEe4fL2-Xoe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict gender probability function (Male, Female probabilities)\n",
        "def predict_gender_prob(text, model, tokenizer, device, max_length=128):\n",
        "    model.eval()\n",
        "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        softmax = torch.nn.Softmax(dim=1)\n",
        "        probabilities = softmax(outputs.logits).cpu().numpy()\n",
        "    return probabilities"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:34.168757Z",
          "iopub.execute_input": "2025-03-19T17:28:34.169049Z",
          "iopub.status.idle": "2025-03-19T17:28:34.238430Z",
          "shell.execute_reply.started": "2025-03-19T17:28:34.169018Z",
          "shell.execute_reply": "2025-03-19T17:28:34.237651Z"
        },
        "id": "RcrbKctl-Xoe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict instance function (Wrapper to call predict_gender_prob)\n",
        "def predict_instance(text):\n",
        "    preds = predict_gender_prob(text, model, tokenizer, device)\n",
        "    # Return as dictionary with 'Male' and 'Female' probabilities\n",
        "    return preds"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:34.239189Z",
          "iopub.execute_input": "2025-03-19T17:28:34.239464Z",
          "iopub.status.idle": "2025-03-19T17:28:34.253237Z",
          "shell.execute_reply.started": "2025-03-19T17:28:34.239442Z",
          "shell.execute_reply": "2025-03-19T17:28:34.252479Z"
        },
        "id": "F47u4pob-Xoe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "txt = \"I've had the 50watter since Oct of last year and I'm still impressed and blown away every time I play it. It's unreal. Killer choice\"\n",
        "predict_male_or_female(txt, model, tokenizer, device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:34.254056Z",
          "iopub.execute_input": "2025-03-19T17:28:34.254344Z",
          "iopub.status.idle": "2025-03-19T17:28:34.654898Z",
          "shell.execute_reply.started": "2025-03-19T17:28:34.254318Z",
          "shell.execute_reply": "2025-03-19T17:28:34.654176Z"
        },
        "id": "FxYqDOCI-Xof"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"You l've got a good man there hun. Take care of each other and it'll last a long time.\\nFor sore throats my dad used to take 2 tablespoons of apple cider vinegar and the same amount of honey, mix it in at least 8oz of hot water. Drink it while ot's still hot, but not burning. Worked every time for me...still does.\"\n",
        "predict_male_or_female(txt, model, tokenizer, device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:34.655576Z",
          "iopub.execute_input": "2025-03-19T17:28:34.655813Z",
          "iopub.status.idle": "2025-03-19T17:28:34.672405Z",
          "shell.execute_reply.started": "2025-03-19T17:28:34.655793Z",
          "shell.execute_reply": "2025-03-19T17:28:34.671610Z"
        },
        "id": "bxwfvxLB-Xof"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from lime.lime_text import LimeTextExplainer, IndexedString\n",
        "import numpy as np\n",
        "from operator import itemgetter\n",
        "from tqdm import tqdm\n",
        "import csv"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:45.351647Z",
          "iopub.execute_input": "2025-03-19T17:28:45.351946Z",
          "iopub.status.idle": "2025-03-19T17:28:45.447417Z",
          "shell.execute_reply.started": "2025-03-19T17:28:45.351907Z",
          "shell.execute_reply": "2025-03-19T17:28:45.446713Z"
        },
        "id": "EmqU5ePY-Xof"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# LIME explainer\n",
        "class_names = ['Democrat', 'Republican']\n",
        "explainer = LimeTextExplainer(class_names=class_names, random_state=42)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:45.448796Z",
          "iopub.execute_input": "2025-03-19T17:28:45.449101Z",
          "iopub.status.idle": "2025-03-19T17:28:45.453625Z",
          "shell.execute_reply.started": "2025-03-19T17:28:45.449079Z",
          "shell.execute_reply": "2025-03-19T17:28:45.452631Z"
        },
        "id": "Uizqda0X-Xof"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort tuples array by second item\n",
        "def sort_tuples_array_by_second_item(tuples):\n",
        "    return sorted(tuples, key=itemgetter(1))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:45.454666Z",
          "iopub.execute_input": "2025-03-19T17:28:45.455220Z",
          "iopub.status.idle": "2025-03-19T17:28:45.470342Z",
          "shell.execute_reply.started": "2025-03-19T17:28:45.455190Z",
          "shell.execute_reply": "2025-03-19T17:28:45.469488Z"
        },
        "id": "GGxAIuRv-Xof"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Get max explained words function\n",
        "def get_max_explained_words(txt, explainer_num_samples=100):\n",
        "    prediction = predict_male_or_female(txt, model, tokenizer, device)\n",
        "    prediction_label = 0 if prediction == \"Democrat\" else 1\n",
        "\n",
        "    indexed_string = IndexedString(txt, bow=explainer.bow, split_expression=explainer.split_expression,\n",
        "                                 mask_string=explainer.mask_string) # Access from explainer object\n",
        "    if indexed_string.num_words() == 0:\n",
        "        print(f\"Warning: Skipping tweet with no recognized words: {txt}\")\n",
        "        return words, wordsForCSV\n",
        "\n",
        "    exp = explainer.explain_instance(txt, predict_instance, num_samples=explainer_num_samples)\n",
        "    exp_list = []\n",
        "    for x in zip(exp.local_exp[1], exp.as_list()):\n",
        "        exp_list.append((x[1][0], x[1][1], x[0][0]))\n",
        "\n",
        "    # Features with negative score are for Male class\n",
        "    male_list = list(filter(lambda x: x[1] < 0, exp_list))\n",
        "    male_list = sort_tuples_array_by_second_item(male_list)\n",
        "\n",
        "    # Features with positive score are for Female class\n",
        "    female_list = list(filter(lambda x: x[1] > 0, exp_list))\n",
        "    female_list = sort_tuples_array_by_second_item(female_list)\n",
        "\n",
        "    # If comment predicted Male\n",
        "    if prediction_label == 0:\n",
        "        if len(male_list) > 1:\n",
        "            male_mc = male_list[0]\n",
        "            if (male_mc[0], 0) in words:\n",
        "                words[(male_mc[0], 0)]['lime_score'].append(male_mc[1])\n",
        "                words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "            else:\n",
        "                words[(male_mc[0], 0)] = {}\n",
        "                words[(male_mc[0], 0)]['lime_score'] = [male_mc[1]]\n",
        "                words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "                wordsForCSV.append([male_mc[0], 0, male_mc[1]])\n",
        "\n",
        "            male_mc = male_list[1]\n",
        "            if (male_mc[0], 0) in words:\n",
        "                words[(male_mc[0], 0)]['lime_score'].append(male_mc[1])\n",
        "                words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "            else:\n",
        "                words[(male_mc[0], 0)] = {}\n",
        "                words[(male_mc[0], 0)]['lime_score'] = [male_mc[1]]\n",
        "                words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
        "                wordsForCSV.append([male_mc[0], 0, male_mc[1]])\n",
        "    else:\n",
        "        if len(female_list) > 1:\n",
        "            female_mc = female_list[(len(female_list)-1)]\n",
        "            if (female_mc[0], 1) in words:\n",
        "                words[(female_mc[0], 1)]['lime_score'].append(female_mc[1])\n",
        "                words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "            else:\n",
        "                words[(female_mc[0], 1)] = {}\n",
        "                words[(female_mc[0], 1)]['lime_score'] = [female_mc[1]]\n",
        "                words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "                wordsForCSV.append([female_mc[0], 1, female_mc[1]])\n",
        "\n",
        "            female_mc = female_list[(len(female_list)-2)]\n",
        "            if (female_mc[0], 1) in words:\n",
        "                words[(female_mc[0], 1)]['lime_score'].append(female_mc[1])\n",
        "                words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "            else:\n",
        "                words[(female_mc[0], 1)] = {}\n",
        "                words[(female_mc[0], 1)]['lime_score'] = [female_mc[1]]\n",
        "                words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
        "                wordsForCSV.append([female_mc[0], 1, female_mc[1]])\n",
        "\n",
        "    return words, wordsForCSV"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:45.633482Z",
          "iopub.execute_input": "2025-03-19T17:28:45.633787Z",
          "iopub.status.idle": "2025-03-19T17:28:45.645475Z",
          "shell.execute_reply.started": "2025-03-19T17:28:45.633762Z",
          "shell.execute_reply": "2025-03-19T17:28:45.644615Z"
        },
        "id": "fvo23ybd-Xof"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from CSV\n",
        "def load_original_data(data_file):\n",
        "    df = pd.read_csv(data_file)\n",
        "    df.fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
        "    comments = df['Tweet'].tolist()\n",
        "    genders = df['Party'].map(lambda x: 0 if x == \"Democrat\" else 1).tolist()\n",
        "    return comments, genders"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:47.010310Z",
          "iopub.execute_input": "2025-03-19T17:28:47.010605Z",
          "iopub.status.idle": "2025-03-19T17:28:47.014930Z",
          "shell.execute_reply.started": "2025-03-19T17:28:47.010580Z",
          "shell.execute_reply": "2025-03-19T17:28:47.013999Z"
        },
        "id": "Cdrl72x5-Xof"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load original data\n",
        "original_comments, original_genders = load_original_data('/kaggle/input/tweet-dataset/Tweets Dataset.csv')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:47.202054Z",
          "iopub.execute_input": "2025-03-19T17:28:47.202322Z",
          "iopub.status.idle": "2025-03-19T17:28:47.477012Z",
          "shell.execute_reply.started": "2025-03-19T17:28:47.202297Z",
          "shell.execute_reply": "2025-03-19T17:28:47.476323Z"
        },
        "id": "qa9z0XU5-Xof"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(len(original_comments) / 3)\n",
        "x = [original_comments[i:i + n] for i in range(0, len(original_comments), n)]\n",
        "y = [original_genders[i:i + n] for i in range(0, len(original_genders), n)]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:48.675829Z",
          "iopub.execute_input": "2025-03-19T17:28:48.676127Z",
          "iopub.status.idle": "2025-03-19T17:28:48.682498Z",
          "shell.execute_reply.started": "2025-03-19T17:28:48.676105Z",
          "shell.execute_reply": "2025-03-19T17:28:48.681716Z"
        },
        "id": "WrVpx4_K-Xof"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables\n",
        "header = [\"word\", \"label\", \"limescore\"]\n",
        "file_path = '/kaggle/working/file.csv'\n",
        "words = {}\n",
        "wordsForCSV = []"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:50.552362Z",
          "iopub.execute_input": "2025-03-19T17:28:50.552675Z",
          "iopub.status.idle": "2025-03-19T17:28:50.556505Z",
          "shell.execute_reply.started": "2025-03-19T17:28:50.552649Z",
          "shell.execute_reply": "2025-03-19T17:28:50.555819Z"
        },
        "id": "OOggVGql-Xof"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for comment in tqdm(x[0], total=len(x[0])):\n",
        "    words, wordsForCSV = get_max_explained_words(comment)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:28:52.252339Z",
          "iopub.execute_input": "2025-03-19T17:28:52.252633Z",
          "iopub.status.idle": "2025-03-19T20:43:11.847630Z",
          "shell.execute_reply.started": "2025-03-19T17:28:52.252608Z",
          "shell.execute_reply": "2025-03-19T20:43:11.846752Z"
        },
        "id": "oq-T9y3A-Xog"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Write results to CSV\n",
        "with open(file_path, 'w', encoding='UTF8', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(wordsForCSV)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T20:43:11.849006Z",
          "iopub.execute_input": "2025-03-19T20:43:11.849270Z",
          "iopub.status.idle": "2025-03-19T20:43:11.886113Z",
          "shell.execute_reply.started": "2025-03-19T20:43:11.849247Z",
          "shell.execute_reply": "2025-03-19T20:43:11.885315Z"
        },
        "id": "8hcx4bgb-Xog"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for comment in tqdm(x[1], total=len(x[1])):\n",
        "    words, wordsForCSV = get_max_explained_words(comment)\n",
        "\n",
        "with open(file_path, 'a', encoding='UTF8', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(wordsForCSV)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T20:43:11.887628Z",
          "iopub.execute_input": "2025-03-19T20:43:11.887927Z",
          "execution_failed": "2025-03-20T01:56:18.868Z"
        },
        "id": "_n9cMDvn-Xog"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for comment in tqdm(x[2], total=len(x[2])):\n",
        "    words, wordsForCSV = get_max_explained_words(comment)\n",
        "\n",
        "with open(file_path, 'a', encoding='UTF8', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(wordsForCSV)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-03-20T01:56:18.868Z"
        },
        "id": "fdTGofAq-Xog"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}