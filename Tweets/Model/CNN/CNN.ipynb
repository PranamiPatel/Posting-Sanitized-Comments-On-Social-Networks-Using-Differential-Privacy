{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "613jw8t0AOsj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xScoxDQAOsm"
      },
      "outputs": [],
      "source": [
        "def load_data(data_file):\n",
        "  # read csv file\n",
        "  df = pd.read_csv(data_file)\n",
        "  df.fillna(\"\", inplace=True)\n",
        "  df = df.drop_duplicates()\n",
        "  comments = df['Tweet'].tolist()\n",
        "  genders = df['Party'].tolist()\n",
        "  genders = [0 if gender == \"Democrat\" else 1 for gender in genders]\n",
        "\n",
        "  return comments, genders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfK6NrUuAOsn"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "file_path = \"C:/Users/ADMIN PC/Desktop/Tweet/Tweets Dataset.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGqbyiZHAOsn"
      },
      "outputs": [],
      "source": [
        "tweet, label = load_data(file_path)\n",
        "tweets = np.array(tweet)\n",
        "labels = np.array(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh0lr73wAOsn"
      },
      "outputs": [],
      "source": [
        "MAX_SEQUENCE_LENGTH = 300\n",
        "MAX_NUM_WORDS = 50000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wOUs84-AOsn"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIGyRFpzAOsn"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts(tweet)\n",
        "sequences = tokenizer.texts_to_sequences(tweet)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQQ0q_0hAOso"
      },
      "outputs": [],
      "source": [
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "labels = to_categorical(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_muB-kpAOso"
      },
      "outputs": [],
      "source": [
        "data.shape, labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTZG-RyqAOso"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, labels,\n",
        "                                                    test_size=0.2,\n",
        "                                                    stratify=labels,\n",
        "                                                    random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4N2kXSWAOsp"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 768\n",
        "num_words = MAX_NUM_WORDS\n",
        "embedding_layer = Embedding(num_words,EMBEDDING_DIM,input_length=MAX_SEQUENCE_LENGTH,trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnzlnaI-AOsp"
      },
      "outputs": [],
      "source": [
        "sequence_input = Input(shape=(300, ))\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "x = Conv1D(64, kernel_size=3, activation='relu')(embedded_sequences)\n",
        "x = Conv1D(64, kernel_size=3, activation='relu')(x)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(100, activation='relu')(x)\n",
        "preds = Dense(2, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(sequence_input, preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Haa0Y8gCAOsp"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_5zexPcAOsp"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfl1QaYxAOsp"
      },
      "outputs": [],
      "source": [
        "# Train the model with validation data\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9k8Aup-AOsp"
      },
      "outputs": [],
      "source": [
        "model.save(\"C:/Users/ADMIN PC/Desktop/Tweet/CNN/CNN.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mJP7F_1AOsp"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('C:/Users/ADMIN PC/Desktop/Tweet/CNN/CNN.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2v1KcXMAOsp"
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0EeBb3UAOsq"
      },
      "outputs": [],
      "source": [
        "def predict_proba(arr):\n",
        "    sequences_new = tokenizer.texts_to_sequences(arr)\n",
        "    data = pad_sequences(sequences_new, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    yprob = model.predict(data, verbose=0)\n",
        "    return yprob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHPK3XStAOsq"
      },
      "outputs": [],
      "source": [
        "def predict_party(text):\n",
        "    \"\"\"Predicts party label based on text.\"\"\"\n",
        "    arr = np.array([text])  # Wrap text in an array\n",
        "    yprob = predict_proba(arr)[0]\n",
        "\n",
        "    return \"Democrat\" if np.argmax(yprob) == 0 else \"Republican\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWST0zk0AOsq"
      },
      "outputs": [],
      "source": [
        "tweet = \"Hurricane Maria left approx $90 billion in damages, yet only $1 billion was allocated for rebuilding grid. No surprâ€¦ https://t.co/2kU8BcKwUh\"\n",
        "print(predict_party(tweet))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5gYYaxGAOsq"
      },
      "outputs": [],
      "source": [
        "tweet = \"Check out my op-ed on need for End Executive Overreach Act: The White House is crippling our economy https://t.co/XCmjLB8Qyd via @DCExaminer\"\n",
        "print(predict_party(tweet))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:anaconda3] *",
      "language": "python",
      "name": "conda-env-anaconda3-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}