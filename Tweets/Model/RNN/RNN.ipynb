{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNiwLGeyItNQtRp0NGfuUEh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKkmC6IUt8jS",
        "outputId": "5ac174d4-c2c8-4399-84b8-921dfb95cb50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense , Input , LSTM , Embedding\n",
        "from tensorflow.keras.models import Model, Sequential"
      ],
      "metadata": {
        "id": "IOci-tfJuFrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "file_path = \"/content/drive/MyDrive/Project/Tweet/Tweets Dataset.csv\""
      ],
      "metadata": {
        "id": "BMAhdE0suQ5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_file):\n",
        "  df = pd.read_csv(data_file)\n",
        "\n",
        "  # replace nan(no value) comment with \"\"(empty string)\n",
        "  df.fillna(\"\", inplace=True)\n",
        "\n",
        "  Tweet = df['Tweet'].tolist()\n",
        "  Partys = df['Party'].tolist()\n",
        "\n",
        "  Party = [0 if Party == \"Democrat\" else 1 for Party in Partys]\n",
        "\n",
        "  return Tweet, Party"
      ],
      "metadata": {
        "id": "uPJV7JiEuWs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet, label = load_data(file_path)\n",
        "tweets = np.array(tweet)\n",
        "labels = np.array(label)"
      ],
      "metadata": {
        "id": "8136UNPaucNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tweets, labels,\n",
        "                                                    test_size=0.2,\n",
        "                                                    stratify=labels,\n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "Pc8iy_Ewudly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_words = 50000\n",
        "max_comment_length = 300\n",
        "embedding_vecor_length = 768"
      ],
      "metadata": {
        "id": "fdp1LjP4ufgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=top_words)"
      ],
      "metadata": {
        "id": "Bis6YvP6ugny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "8CZstMIquhqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_comment_length)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_comment_length)"
      ],
      "metadata": {
        "id": "1UAKwHLfuinR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=top_words+1, output_dim=embedding_vecor_length, input_length=max_comment_length),\n",
        "    LSTM(100, return_sequences=False),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.build(input_shape=(None, max_comment_length))"
      ],
      "metadata": {
        "id": "mPicpS6Nujlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "tUODLcE9ukwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "IcthHcrmul4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_pad, y_train,\n",
        "                    validation_data=(X_test_pad, y_test),\n",
        "                    epochs=4,\n",
        "                    batch_size=64,\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "id": "5S3B7O2uum9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/Project/Tweet/RNN/RNN.h5\")"
      ],
      "metadata": {
        "id": "BPK2tgS6uo5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(\"/content/drive/MyDrive/Project/Tweet/RNN/RNN.h5\")"
      ],
      "metadata": {
        "id": "-82s6mY9utrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_tokenized_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_test = pad_sequences(list_tokenized_test, maxlen=max_comment_length)\n",
        "prediction = model.predict(X_test)\n",
        "y_pred = (prediction > 0.5)\n",
        "print(\"Accuracy of the model : \", accuracy_score(y_pred, y_test))"
      ],
      "metadata": {
        "id": "raTOT4you2_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_party(comment):\n",
        "    comment_seq = tokenizer.texts_to_sequences([comment])\n",
        "    comment_pad = pad_sequences(comment_seq, maxlen=max_comment_length)\n",
        "    prob = model.predict(comment_pad)[0][0]\n",
        "    gender = \"Republican\" if prob >= 0.5 else \"Democrat\"\n",
        "\n",
        "    return gender"
      ],
      "metadata": {
        "id": "hijVmKxMu3wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_probability(comments):\n",
        "    comment_seq = tokenizer.texts_to_sequences(comments)\n",
        "    comment_pad = pad_sequences(comment_seq, maxlen=max_comment_length)\n",
        "    probs = model.predict(comment_pad)\n",
        "    probs = np.column_stack([1 - probs, probs])  # [Democrat, Republican]\n",
        "\n",
        "    return probs"
      ],
      "metadata": {
        "id": "rgR-g4F6u32S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = \"Hurricane Maria left approx $90 billion in damages, yet only $1 billion was allocated for rebuilding grid. No surprâ€¦ https://t.co/2kU8BcKwUh\"\n",
        "print(predict_party(tweet))"
      ],
      "metadata": {
        "id": "eqfat5EUu6OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = \"Check out my op-ed on need for End Executive Overreach Act: The White House is crippling our economy https://t.co/XCmjLB8Qyd via @DCExaminer\"\n",
        "predict_party(tweet)"
      ],
      "metadata": {
        "id": "EDoIi39cu6Rm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}