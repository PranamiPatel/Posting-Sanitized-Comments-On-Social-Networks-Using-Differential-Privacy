{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fec6e65e-f51e-4cde-bde7-71d3f70a72b3",
      "metadata": {
        "id": "fec6e65e-f51e-4cde-bde7-71d3f70a72b3"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3557790c-9205-4081-bb47-e4a030193c43",
      "metadata": {
        "collapsed": true,
        "id": "3557790c-9205-4081-bb47-e4a030193c43",
        "outputId": "10245e85-5b6c-4cd6-86b8-98e9569ede70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c653d8d6-8e44-4d8c-8a9c-3898e1f4f77b",
      "metadata": {
        "id": "c653d8d6-8e44-4d8c-8a9c-3898e1f4f77b"
      },
      "outputs": [],
      "source": [
        "strong_word_file = pd.read_csv(\"C:/Users/user/Downloads/Project/Comment/RNN/extracted_strong_word_by_rnn.csv\")\n",
        "original_data = pd.read_csv(\"C:/Users/user/Downloads/Project/Comment/Comment_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8176ab0f-a891-431c-9ef0-96155d802b45",
      "metadata": {
        "collapsed": true,
        "id": "8176ab0f-a891-431c-9ef0-96155d802b45",
        "outputId": "39a35efe-d500-4d75-f389-a5380c41d828"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>label</th>\n",
              "      <th>limescore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jess</td>\n",
              "      <td>1</td>\n",
              "      <td>0.140988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wow</td>\n",
              "      <td>1</td>\n",
              "      <td>0.086389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Beautiful</td>\n",
              "      <td>1</td>\n",
              "      <td>0.327962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>u</td>\n",
              "      <td>1</td>\n",
              "      <td>0.043168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>some</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.140177</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        word  label  limescore\n",
              "0       jess      1   0.140988\n",
              "1        wow      1   0.086389\n",
              "2  Beautiful      1   0.327962\n",
              "3          u      1   0.043168\n",
              "4       some      0  -0.140177"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "strong_word_file.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44438b53-0e15-438d-8ec5-ad7111ca9c5b",
      "metadata": {
        "id": "44438b53-0e15-438d-8ec5-ad7111ca9c5b"
      },
      "outputs": [],
      "source": [
        "symbols_dict = {\n",
        "    '!': 'Exclamation Mark',\n",
        "    '\"': 'Double Quotation Mark',\n",
        "    '#': 'Hash/Pound Sign',\n",
        "    '$': 'Dollar Sign',\n",
        "    '%': 'Percent Sign',\n",
        "    '&': 'Ampersand',\n",
        "    \"'\": 'Single Quotation Mark',\n",
        "    '(': 'Left Parenthesis',\n",
        "    ')': 'Right Parenthesis',\n",
        "    '*': 'Asterisk',\n",
        "    '+': 'Plus Sign',\n",
        "    ',': 'Comma',\n",
        "    '-': 'Hyphen',\n",
        "    '.': 'Period',\n",
        "    '/': 'Forward Slash',\n",
        "    ':': 'Colon',\n",
        "    ';': 'Semicolon',\n",
        "    '<': 'Less Than Sign',\n",
        "    '=': 'Equal Sign',\n",
        "    '>': 'Greater Than Sign',\n",
        "    '?': 'Question Mark',\n",
        "    '@': 'At Sign',\n",
        "    '[': 'Left Square Bracket',\n",
        "    ']': 'Right Square Bracket',\n",
        "    '^': 'Caret',\n",
        "    '_': 'Underscore',\n",
        "    '`': 'Backtick',\n",
        "    '{': 'Left Curly Brace',\n",
        "    '|': 'Vertical Bar',\n",
        "    '}': 'Right Curly Brace',\n",
        "    '~': 'Tilde',\n",
        "    '...': 'Three Dots'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c526b4eb-1d4a-40c9-8eb4-3cb4689ea266",
      "metadata": {
        "id": "c526b4eb-1d4a-40c9-8eb4-3cb4689ea266"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5946e632-99d1-42f4-bdf8-3a285ec8b9dd",
      "metadata": {
        "id": "5946e632-99d1-42f4-bdf8-3a285ec8b9dd"
      },
      "outputs": [],
      "source": [
        "glove_model = api.load(\"glove-wiki-gigaword-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d626b29-82c0-4a56-908c-70e03e481625",
      "metadata": {
        "id": "8d626b29-82c0-4a56-908c-70e03e481625"
      },
      "outputs": [],
      "source": [
        "def prepare_Vs(comment, label, strong_word_file, n) :\n",
        "    tokens = word_tokenize(str(comment).lower())\n",
        "    Vs, Vn = [], []\n",
        "\n",
        "    for token in tokens :\n",
        "        strong_word = strong_word_file[strong_word_file['word'] == token]\n",
        "        if not strong_word.empty and strong_word['label'].values[0] == label :\n",
        "            Vs.append((token, strong_word['limescore'].values[0]))\n",
        "        else :\n",
        "            Vn.append(token)\n",
        "\n",
        "    Vs.sort(key=lambda x: x[1], reverse=True)\n",
        "    Vn.extend([word for word, _ in Vs[n:]])\n",
        "    Vs = [word for word, _ in Vs[:n]]\n",
        "\n",
        "    return Vs, Vn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edbb1494-87b7-4073-8084-3d3f28eb97bf",
      "metadata": {
        "id": "edbb1494-87b7-4073-8084-3d3f28eb97bf"
      },
      "outputs": [],
      "source": [
        "def d_angular(x,y):\n",
        "    dot_product = np.dot(x, y)\n",
        "    norm_x = np.linalg.norm(x)\n",
        "    norm_y = np.linalg.norm(y)\n",
        "\n",
        "    cosine_similarity = dot_product / (norm_x * norm_y)\n",
        "    cosine_similarity = np.clip(cosine_similarity, -1.0, 1.0)\n",
        "    angular_distance_radians = np.arccos(cosine_similarity)\n",
        "\n",
        "    return angular_distance_radians"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55cfdf9a-ee9b-4b9e-a9c2-348d4d4adcd8",
      "metadata": {
        "id": "55cfdf9a-ee9b-4b9e-a9c2-348d4d4adcd8"
      },
      "outputs": [],
      "source": [
        "def compute_probability(x, y, Vp, epsilon):\n",
        "\n",
        "    x_vec = glove_model[x]\n",
        "    y_vec = glove_model[y]\n",
        "    d_angular_sim = d_angular(x_vec, y_vec)\n",
        "\n",
        "    sum_exp = 0\n",
        "    for v in Vp:\n",
        "        if v in glove_model:\n",
        "            sum_exp += np.exp(-0.5 * epsilon * d_angular(x_vec, glove_model[v]))\n",
        "\n",
        "    # Prevent division by zero\n",
        "    Cx = 1 / sum_exp if sum_exp != 0 else 1\n",
        "    prob = Cx * np.exp(-0.5 * epsilon * d_angular_sim)\n",
        "    return prob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56430b7d-4d70-45c5-9eb3-b1c35958b33e",
      "metadata": {
        "id": "56430b7d-4d70-45c5-9eb3-b1c35958b33e"
      },
      "outputs": [],
      "source": [
        "# Function to find top N semantically similar words\n",
        "def get_top_similar_words(word, model, top_n):\n",
        "    threshold = 0.6\n",
        "    try:\n",
        "        similar_words = model.most_similar(word, topn=top_n*2)\n",
        "        return [item[0] for item in similar_words if item[1] >= threshold][:top_n]\n",
        "    except KeyError:\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e451798f-e609-4f8f-8388-ccfc132c5a98",
      "metadata": {
        "id": "e451798f-e609-4f8f-8388-ccfc132c5a98"
      },
      "outputs": [],
      "source": [
        "def substitute_word(word, Vp, epsilon):\n",
        "    if not Vp:\n",
        "        return word, 0.0\n",
        "\n",
        "    y = np.random.choice(Vp)\n",
        "    prob = compute_probability(word, y, Vp, epsilon)\n",
        "    return y, prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d34cb37",
      "metadata": {
        "id": "1d34cb37"
      },
      "outputs": [],
      "source": [
        "sens_word_dict = {\n",
        "    'he': 'person',\n",
        "    'she': 'person'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "204a8f39-182b-4c3d-a681-9e71313c217f",
      "metadata": {
        "id": "204a8f39-182b-4c3d-a681-9e71313c217f"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "def generator(glove_model, top_strong_word, top_similar_word, epsilon, output_file):\n",
        "    generated_data = []\n",
        "\n",
        "    p = 0.5\n",
        "    for i in tqdm(range(len(original_data)), desc=\"Generating comment\", unit=\"comment\"):\n",
        "        comment = original_data.iloc[i]['comment']\n",
        "        label = original_data.iloc[i]['user_gender']\n",
        "        genders = 0 if label == \"Male\" else 1\n",
        "\n",
        "        Vs, Vn = prepare_Vs(comment, genders, strong_word_file, top_strong_word)\n",
        "\n",
        "        tokens = word_tokenize(comment.lower())\n",
        "        new_comment = []\n",
        "\n",
        "        for word in tokens:\n",
        "\n",
        "            if word in sens_word_dict:\n",
        "              new_comment.append(sens_word_dict[word])\n",
        "\n",
        "            elif word in stop_words or any(ord(c) > 127 for c in word) or word in symbols_dict :\n",
        "                new_comment.append(word)\n",
        "\n",
        "            elif word in Vs :\n",
        "                Vg = get_top_similar_words(word, glove_model, top_similar_word)\n",
        "                Vp = list(set(Vg) - set(Vs))\n",
        "\n",
        "                new_word, prob = substitute_word(word, Vp, epsilon)\n",
        "                new_comment.append(new_word)\n",
        "\n",
        "            else:\n",
        "                flip = random.random()\n",
        "                if flip <= p:\n",
        "                    new_comment.append(word)\n",
        "                else:\n",
        "                    Vg = get_top_similar_words(word, glove_model, top_similar_word)\n",
        "                    Vp = list(set(Vg) - set(Vs))\n",
        "\n",
        "                    new_word, prob = substitute_word(word, Vp, epsilon)\n",
        "                    new_comment.append(new_word)\n",
        "\n",
        "\n",
        "        generated_comment = \" \".join(new_comment)\n",
        "        generated_data.append([comment, generated_comment, label])\n",
        "\n",
        "    generated_df = pd.DataFrame(generated_data, columns=['Original comment', 'Generated comment', 'Label'])\n",
        "    generated_df.to_csv(output_file, index=False)\n",
        "    print(f\"Generated comments saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78c6617f-d6c4-42cf-9fe0-e5b1fb271368",
      "metadata": {
        "collapsed": true,
        "id": "78c6617f-d6c4-42cf-9fe0-e5b1fb271368",
        "outputId": "82ae7240-d7d8-4c7a-c8b5-53d4c6eee213"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating comment: 100%|███████████████████████████████████████████████| 190104/190104 [4:17:53<00:00, 12.29comment/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated comments saved to C:/Users/user/Downloads/Project/Comment/CNN/Using_angular/comment_2_10_10.csv\n"
          ]
        }
      ],
      "source": [
        "generator(glove_model, 2, 10, 1, \"C:/Users/user/Downloads/Project/Comment/RNN/Using_angular/comment_2_10_10.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84e20107-ec1a-4096-98e4-1681c0ec392b",
      "metadata": {
        "collapsed": true,
        "id": "84e20107-ec1a-4096-98e4-1681c0ec392b",
        "outputId": "456b0178-c13f-40ad-b8bf-0b6fe3ea8ed0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating comment: 100%|███████████████████████████████████████████████| 190104/190104 [4:06:55<00:00, 12.83comment/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated comments saved to C:/Users/user/Downloads/Project/Comment/RNN/Using_angular/comment_2_15_10.csv\n"
          ]
        }
      ],
      "source": [
        "generator(glove_model, 2, 15, 1, \"C:/Users/user/Downloads/Project/Comment/RNN/Using_angular/comment_2_15_10.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "260440fe-6754-4c6b-be30-46fb129de77f",
      "metadata": {
        "collapsed": true,
        "id": "260440fe-6754-4c6b-be30-46fb129de77f",
        "outputId": "cc548014-47bb-40c2-b19d-c2223ea74eef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating comment: 100%|███████████████████████████████████████████████| 190104/190104 [4:11:14<00:00, 12.61comment/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated comments saved to C:/Users/user/Downloads/Project/Comment/RNN/Using_angular/comment_3_10_10.csv\n"
          ]
        }
      ],
      "source": [
        "generator(glove_model, 3, 10, 1, \"C:/Users/user/Downloads/Project/Comment/RNN/Using_angular/comment_3_10_10.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "708505cf-2983-4da0-ac59-03f698996c4b",
      "metadata": {
        "collapsed": true,
        "id": "708505cf-2983-4da0-ac59-03f698996c4b",
        "outputId": "266b6c79-a72d-4701-c6bc-d0e9ca9afe28"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating comment: 100%|███████████████████████████████████████████████| 190104/190104 [4:02:34<00:00, 13.06comment/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated comments saved to C:/Users/user/Downloads/Project/Comment/RNN/Using_angular/comment_3_15_10.csv\n"
          ]
        }
      ],
      "source": [
        "generator(glove_model, 3, 15, 1, \"C:/Users/user/Downloads/Project/Comment/RNN/Using_angular/comment_3_15_10.csv\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:anaconda3] *",
      "language": "python",
      "name": "conda-env-anaconda3-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}