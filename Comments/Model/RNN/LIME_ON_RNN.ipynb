{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Uur0S6WDyQVC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense , Input , LSTM , Embedding\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "f4cYcfUuy5Hk"
   },
   "outputs": [],
   "source": [
    "top_words = 10000\n",
    "max_comment_length = 300\n",
    "embedding_vecor_length = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0FMNwLd7yQVD"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"C:/Users/user/Downloads/Project/Comment/RNN/RNN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8nA8GomrA-u"
   },
   "outputs": [],
   "source": [
    "def predict_male_or_female(comment):\n",
    "    comment_seq = tokenizer.texts_to_sequences([comment])\n",
    "    comment_pad = pad_sequences(comment_seq, maxlen=max_comment_length)\n",
    "    prob = model.predict(comment_pad)[0][0]\n",
    "    gender = \"Female\" if prob >= 0.5 else \"Male\"\n",
    "\n",
    "    return gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "8N5_jZxfsgjP"
   },
   "outputs": [],
   "source": [
    "def predict_probability(comments):\n",
    "    if isinstance(comments, str):\n",
    "        comments = [comments]\n",
    "\n",
    "    comment_seq = tokenizer.texts_to_sequences(comments)\n",
    "    comment_pad = pad_sequences(comment_seq, maxlen=max_comment_length)\n",
    "    probs = model.predict(comment_pad)\n",
    "    probs = np.column_stack([1 - probs, probs])  # [Male_prob, Female_prob]\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IB29d5Qzsglt",
    "outputId": "4a38888e-1a17-4200-8822-5d4d04f3fb16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step\n",
      "Male\n"
     ]
    }
   ],
   "source": [
    "txt = \"I've had the 50watter since Oct of last year and I'm still impressed and blown away every time I play it. It's unreal. Killer choice\"\n",
    "print(predict_male_or_female(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-u9q2WHtcJt",
    "outputId": "47ffa767-7cf5-498b-cdc9-ffce118cacc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step\n",
      "Female\n"
     ]
    }
   ],
   "source": [
    "txt = \"This is a great picture of u!!!! Beautiful\"\n",
    "print(predict_male_or_female(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "from operator import itemgetter\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Male', 'Female']\n",
    "explainer = LimeTextExplainer(class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with an explainer (assuming LIME explainer)\n",
    "txt = \"I've had the 50watter since Oct of last year and I'm still impressed and blown away every time I play it. It's unreal. Killer choice\"\n",
    "explainer.explain_instance(txt, predict_probability).show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"This is a great picture of u!!!! Beautiful\"\n",
    "explainer.explain_instance(txt, predict_probability).show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort tuples array by second item\n",
    "def sort_tuples_array_by_second_item(tuples):\n",
    "    return sorted(tuples, key=itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get max explained words\n",
    "def get_max_explained_words(txt, explainer_num_samples=100):\n",
    "    prediction = predict_male_or_female(txt)\n",
    "    prediction_label = 0 if prediction == \"Male\" else 1\n",
    "\n",
    "    exp = explainer.explain_instance(txt, predict_probability, num_samples=explainer_num_samples)\n",
    "    exp_list = []\n",
    "    for x in zip(exp.local_exp[1], exp.as_list()):\n",
    "        exp_list.append((x[1][0], x[1][1], x[0][0]))\n",
    "\n",
    "    # Features with negative score are for Male class\n",
    "    male_list = list(filter(lambda x: x[1] < 0, exp_list))\n",
    "    male_list = sort_tuples_array_by_second_item(male_list)\n",
    "\n",
    "    # Features with positive score are for Female class\n",
    "    female_list = list(filter(lambda x: x[1] > 0, exp_list))\n",
    "    female_list = sort_tuples_array_by_second_item(female_list)\n",
    "\n",
    "    # If comment predicted Male\n",
    "    if prediction_label == 0:\n",
    "        if len(male_list) > 1:\n",
    "            male_mc = male_list[0]\n",
    "            if (male_mc[0], 0) in words:\n",
    "                words[(male_mc[0], 0)]['lime_score'].append(male_mc[1])\n",
    "                words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
    "            else:\n",
    "                words[(male_mc[0], 0)] = {}\n",
    "                words[(male_mc[0], 0)]['lime_score'] = [male_mc[1]]\n",
    "                words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
    "                wordsForCSV.append([male_mc[0], 0, male_mc[1]])\n",
    "\n",
    "            male_mc = male_list[1]\n",
    "            if (male_mc[0], 0) in words:\n",
    "                words[(male_mc[0], 0)]['lime_score'].append(male_mc[1])\n",
    "                words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
    "            else:\n",
    "                words[(male_mc[0], 0)] = {}\n",
    "                words[(male_mc[0], 0)]['lime_score'] = [male_mc[1]]\n",
    "                words[(male_mc[0], 0)]['position'] = male_mc[2]\n",
    "                wordsForCSV.append([male_mc[0], 0, male_mc[1]])\n",
    "    else:\n",
    "        if len(female_list) > 1:\n",
    "            female_mc = female_list[(len(female_list) - 1)]\n",
    "            if (female_mc[0], 1) in words:\n",
    "                words[(female_mc[0], 1)]['lime_score'].append(female_mc[1])\n",
    "                words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
    "            else:\n",
    "                words[(female_mc[0], 1)] = {}\n",
    "                words[(female_mc[0], 1)]['lime_score'] = [female_mc[1]]\n",
    "                words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
    "                wordsForCSV.append([female_mc[0], 1, female_mc[1]])\n",
    "\n",
    "            female_mc = female_list[(len(female_list) - 2)]\n",
    "            if (female_mc[0], 1) in words:\n",
    "                words[(female_mc[0], 1)]['lime_score'].append(female_mc[1])\n",
    "                words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
    "            else:\n",
    "                words[(female_mc[0], 1)] = {}\n",
    "                words[(female_mc[0], 1)]['lime_score'] = [female_mc[1]]\n",
    "                words[(female_mc[0], 1)]['position'] = female_mc[2]\n",
    "                wordsForCSV.append([female_mc[0], 1, female_mc[1]])\n",
    "\n",
    "    return words, wordsForCSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_original_data(data_file):\n",
    "  df = pd.read_csv(data_file)\n",
    "  df.fillna(\"\", inplace=True)\n",
    "  comments = df['comment'].tolist()\n",
    "  genders = df['user_gender'].tolist()\n",
    "  genders = [0 if gender == \"Male\" else 1 for gender in genders]\n",
    "\n",
    "  return comments, genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_comments, original_genders = load_original_data('C:/Users/user/Downloads/Project/Comment/Comment_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(original_comments) / 14)\n",
    "x = [original_comments[i:i + n] for i in range(0, len(original_comments), n)]\n",
    "y = [original_genders[i:i + n] for i in range(0, len(original_genders), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "header = [\"word\", \"label\", \"limescore\"]\n",
    "words = {}\n",
    "wordsForCSV = []\n",
    "file_path = 'C:/Users/user/Downloads/Project/Comment/RNN/extracted_strong_words_by_rnn.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Process each chunk of comments\n",
    "for comment in tqdm(x[0], total=len(x[0])):\n",
    "    words, wordsForCSV = get_max_explained_words(comment)\n",
    "\n",
    "with open(file_path, 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(wordsForCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comment in tqdm(x[1], total=len(x[1])):\n",
    "    words, wordsForCSV = get_max_explained_words(comment)\n",
    "\n",
    "with open(file_path, 'a', encoding='UTF8', newline='') as f:  \n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(wordsForCSV) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for comment in tqdm(x[2], total=len(x[2])):\n",
    "    words, wordsForCSV = get_max_explained_words(comment)\n",
    "\n",
    "with open(file_path, 'a', encoding='UTF8', newline='') as f:  \n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(wordsForCSV)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comment in tqdm(x[3], total=len(x[3])):\n",
    "    words, wordsForCSV = get_max_explained_words(comment)\n",
    "\n",
    "with open(file_path, 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(wordsForCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comment in tqdm(x[4], total=len(x[4])):\n",
    "    words, wordsForCSV = get_max_explained_words(comment)\n",
    "\n",
    "with open(file_path, 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(wordsForCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comment in tqdm(x[5], total=len(x[5])):\n",
    "    words, wordsForCSV = get_max_explained_words(comment)\n",
    "\n",
    "with open(file_path, 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(wordsForCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comment in tqdm(x[6], total=len(x[6])):\n",
    "    words, wordsForCSV = get_max_explained_words(comment)\n",
    "\n",
    "with open(file_path, 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(wordsForCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comment in tqdm(x[7], total=len(x[7])):\n",
    "    words, wordsForCSV = get_max_explained_words(comment)\n",
    "\n",
    "with open(file_path, 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(wordsForCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comment in tqdm(x[8], total=len(x[8])):\n",
    "    words, wordsForCSV = get_max_explained_words(comment)\n",
    "\n",
    "with open(file_path, 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(wordsForCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comment in tqdm(x[9], total=len(x[9])):\n",
    "    words, wordsForCSV = get_max_explained_words(comment)\n",
    "\n",
    "with open(file_path, 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(wordsForCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comment in tqdm(x[10], total=len(x[10])):\n",
    "    words, wordsForCSV = get_max_explained_words(comment)\n",
    "\n",
    "with open(file_path, 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(wordsForCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comment in tqdm(x[11], total=len(x[11])):\n",
    "    words, wordsForCSV = get_max_explained_words(comment)\n",
    "\n",
    "with open(file_path, 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(wordsForCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comment in tqdm(x[12], total=len(x[12])):\n",
    "    words, wordsForCSV = get_max_explained_words(comment)\n",
    "\n",
    "with open(file_path, 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(wordsForCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comment in tqdm(x[13], total=len(x[13])):\n",
    "    words, wordsForCSV = get_max_explained_words(comment)\n",
    "\n",
    "with open(file_path, 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(wordsForCSV)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6593665,
     "sourceId": 10648868,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3] *",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
